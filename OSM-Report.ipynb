{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling: OpenStreetMap Data\n",
    "\n",
    "\n",
    "\n",
    "## Project Overview\n",
    "To choose an area of the world in https://www.openstreetmap.org and use data munging techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean the OpenStreetMap data for a part of the world that you care about. Finally, use SQL as the data schema to complete your project.\n",
    "\n",
    "## OSM Dataset\n",
    "The area selected on the OpenStreetMap for this project is the city of Houston, Texas. Houston is the city where I currently reside. I moved here only about a year ago. So, I wanted to use this as an opportunity to learn more data based facts about this city and get more familiarized with its geography and general demographics. Moreover, I would like to contribute to its improvement on OpenStreetMap.\n",
    "\n",
    "The data was directly exported as an OSM XML file from the Mapzen Metro extracts:\n",
    "https://mapzen.com/data/metro-extracts/metro/houston_texas/\n",
    "\n",
    "\n",
    "## Data Audit\n",
    "Before starting to work with the entire dataset, an initial investigation of the dataset was conducted on a small sample of the dataset, which revealed problems with the data listed below.  \n",
    "\n",
    "### Probelms with the data\n",
    "1. Inconsistency in Abbreviations of street names(FM, Fm, Farm-to-Martket, Farm to Market)\n",
    "2. Misspelled street names ('Plaze' instead of 'Plaza', 'Westhiemer' spelled as 'Westhimer')\n",
    "2. Incorrect Postal codes ('Weslayan Street' listed in post code field) \n",
    "3. Inconsistent Postal codes formats('77042-9998', 'tx 77042', '77478-', '770764', '773867386') \n",
    "\n",
    "#### Street Names\n",
    "Although there were no major flaws with the street names, we came across many inconsistent abbreviations. For example Dr. dr, DR for Drive, Fwy or Frwy for Freeway etc. The misspelled words ('Plaze' instead of 'Plaza', 'Westhiemer' spelled as 'Westhimer') in street names were also identified and fixed using the mapping dictionary. \n",
    "There were also abbreviations N, E, S and W for North, East, South and West respectively which needed to be fixed. However, there were entries for 'Avenue E'and 'Avenue S' which needed to remain as is. Additionally, there were street names where multiple abbreviations needed to be fixed such as Hwy 6 S. So, instead of using regular expressions, I opted to iterate over each word of the street name correcting them to their respective mappings in audit.py using the following function: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "def update_name(name, mapping):\n",
    "    parts = name.split()\n",
    "    for i in range(len(parts)):\n",
    "        if parts[i] in mapping.keys():\n",
    "            if parts[0] != \"Avenue\":\n",
    "                parts[i] = mapping[parts[i]] \n",
    "                name = \" \".join(parts)\n",
    "    return name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This updated all abbreviations in the street names, example Hwy 6 S => Highway 6 South except where the street was an Avenue.\n",
    "\n",
    "#### Postcodes\n",
    "\n",
    "In the dataset, our initial review revealed that there were many different formats were used for postcodes. In order to bring the consistency in the format, I chose to convert all the postcodes to 5 digit format eg. 77077 using the below function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#Compiling the reg ex to get 5 digit format from bad postcode format\n",
    "#find 5 digit pattern in (5 digits) hyphen 4 digits\n",
    "d5_d4 = re.compile(r'^(7\\d{4})-\\d{4}$') \n",
    "\n",
    "#find 5 digit pattern in two alphabets space (5 digit)\n",
    "str_d5 = re.compile(r'^[a-zA-Z]{2}\\s(\\d{5})$') \n",
    "\n",
    "#(5 digits) followed by more numbers or alphabets in continuation\n",
    "d5_chr  = re.compile(r'^(\\d{5}).+$') \n",
    "\n",
    "\n",
    "def update_postcode(postcode):\n",
    "    if re.match(d5_d4, postcode):\n",
    "        correct_postcode = re.findall(d5_d4,postcode)[0]\n",
    "    elif re.match(str_d5, postcode):\n",
    "        correct_postcode = re.findall(str_d5,postcode)[0]\n",
    "    elif re.match(d5_chr, postcode):\n",
    "        correct_postcode = re.findall(d5_chr, postcode)[0]\n",
    "    else:\n",
    "        return postcode\n",
    "    return correct_postcode\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After auditing was complete, the data was prepared to be inserted into a SQL database. To do so, the elements in the OSM XML file were parsed, transforming them from document format to tabular format, thus making it possible to write to .csv files.  These csv files were then imported to a SQL database as tables using database.py.\n",
    "\n",
    "When the complete database was queried to look at the postcodes, all postcodes were in the 5 digit format except the three postcodes listed below.\n",
    "1. postcode ='\"Weslayan Street' \n",
    "2. postcode = '88581' \n",
    "3. postcode = '7-' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### postcode = 'Weslayan Street'\n",
    "\n",
    "In order to investigate the postcode = 'Weslayan Street', we queried the database to fetch the complete details from the nodes_tags table for this postcode.\n",
    "\n",
    "\n",
    "```\n",
    "SELECT * FROM nodes_tags \n",
    "WHERE id IN \n",
    "(SELECT DISTINCT(id) FROM nodes_tags WHERE key='postcode' AND value='Weslayan Street');\n",
    "```\n",
    "\n",
    "The results were as below\n",
    "\n",
    "```\n",
    "[(u'1812187787', u'atm', u'yes', u'regular'),\n",
    " (u'1812187787', u'name', u'Chase', u'regular'),\n",
    " (u'1812187787', u'amenity', u'bank', u'regular'),\n",
    " (u'1812187787', u'street', u'77027', u'addr'),\n",
    " (u'1812187787', u'postcode', u'Weslayan Street', u'addr'),\n",
    " (u'1812187787', u'housenumber', u'2900', u'addr')]\n",
    "```\n",
    "\n",
    "There must have been a typo error as postcode is in place of street and street name in place of postcode. Since this is just one off query where postcode and street name are switched, I decided to fix it through sql query as below. \n",
    "\n",
    "```\n",
    "UPDATE nodes_tags \n",
    "    SET value = CASE \n",
    "    WHEN key = 'street' \n",
    "        THEN 'Weslayan Street' \n",
    "    WHEN key = 'postcode' \n",
    "        THEN '77027' \n",
    "    ELSE value \n",
    "    END\n",
    "WHERE  id = '1812187787';\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### postcode = '88581'\n",
    "\n",
    "The postcodes \"88581\" stood out as clearly erroneous. This is becuase all of Houston area's postcode begin with '7' as opposed to this one. So, I queried the database to find the complete details from nodes and nodes_tags. Using the latitude and longitude coordinates, we confirmed that the address is in La Porte, which is in Houston Metro area. So, the postcode is definitely incorrect. I queried the database to get the list of cities and the number of tags to make sure if La Porte is indeed in our dataset. \n",
    "\n",
    "```\n",
    "SELECT tags.value, COUNT(*) as count \n",
    "FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "      SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key LIKE '%city'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC;\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "SELECT * FROM nodes \n",
    "WHERE id IN (SELECT DISTINCT(id) FROM nodes_tags WHERE key='postcode' AND value='88581');\n",
    "```\n",
    "\n",
    "Result: \n",
    "\n",
    "```\n",
    "[(u'1924194015',\n",
    "  u'29.6646435',\n",
    "  u'-95.1005174',\n",
    "  u'Mars Is Waiting',\n",
    "  u'901643',\n",
    "  u'1',\n",
    "  u'13188778',\n",
    "  u'2012-09-20T21:09:56Z')]\n",
    "```\n",
    "Also, I queried the nodes_tags table to get the address details for this ID we got from above.\n",
    "\n",
    "```\n",
    "SELECT * FROM nodes_tags WHERE id='1924194015';\n",
    "```\n",
    "```\n",
    "[(u'1924194015', u'name', u'Supercuts', u'regular'),\n",
    " (u'1924194015', u'shop', u'hairdresser', u'regular'),\n",
    " (u'1924194015', u'website', u'www.supercuts.com', u'regular'),\n",
    " (u'1924194015', u'street', u'Spencer Highway', u'addr'),\n",
    " (u'1924194015', u'postcode', u'77571', u'addr'),\n",
    " (u'1924194015', u'housenumber', u'9001', u'addr')]\n",
    "```\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick google search on Supercuts, 9001 Spencer highway revealed that the postcode should \n",
    "be 77571 instead of 88581. So, nodes_tags table was updated to reflect the same.\n",
    "\n",
    "\n",
    "```\n",
    "UPDATE nodes_tags\n",
    "    SET value = '77571' \n",
    "    WHERE id = '1924194015' AND  key = 'postcode' AND value = '88581';\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### postcode = '7-'\n",
    "\n",
    "A similar query as above was done to fetch address details for this postcode. The address was of a mexican restaurant 'Berryhill Tacos Sugarland, 13703  Southwest Freeway. This address was used to find the correct postcode i.e. 77478 and then updated in the database using below query.\n",
    "\n",
    "\n",
    "```\n",
    "UPDATE nodes_tags\n",
    "    SET value = '77478' \n",
    "    WHERE id = '4265057550' AND  key = 'postcode' AND value = '7-';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview And Additional Exploration\n",
    "\n",
    "Before we start the analysis part, lets look at the statistics of our database and its files. \n",
    "```\n",
    "houston_texas.osm: 664 MB\n",
    "OSM_FINAL_DB.db: 580 MB\n",
    "nodes.csv: 246 MB\n",
    "nodes_tags.csv:6 MB\n",
    "ways.csv:21.3 MB\n",
    "ways_tags.csv:67.1 MB\n",
    "ways_nodes.csv:86.9 MB\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db = sqlite3.connect(\"OSM_FINAL_DB.db\")\n",
    "cur = db.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3064419,)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM nodes;\").fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(371640,)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM ways;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1707,)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS users;\")\n",
    "\n",
    "cur.execute(\"\"\" CREATE TABLE users AS\n",
    "                SELECT all_uid.user AS user_name, all_uid.uid AS user_id\n",
    "                FROM \n",
    "                (SELECT user, uid FROM nodes \n",
    "                UNION ALL \n",
    "                SELECT user, uid FROM ways) all_uid; \"\"\")\n",
    "\n",
    "cur.execute(\"\"\" SELECT COUNT(DISTINCT(user_id)) FROM users LIMIT 10; \"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 users\n",
    "\n",
    "Tabular display in sql isn't very beautiful, so I used pandas to get a better formatted table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>contributions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woodpeck_fixbot</td>\n",
       "      <td>147510</td>\n",
       "      <td>565052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TexasNHD</td>\n",
       "      <td>672878</td>\n",
       "      <td>538407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afdreher</td>\n",
       "      <td>1110270</td>\n",
       "      <td>486780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scottyc</td>\n",
       "      <td>496606</td>\n",
       "      <td>204136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cammace</td>\n",
       "      <td>3119079</td>\n",
       "      <td>193856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claysmalley</td>\n",
       "      <td>119881</td>\n",
       "      <td>138030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brianboru</td>\n",
       "      <td>9065</td>\n",
       "      <td>116780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>skquinn</td>\n",
       "      <td>243003</td>\n",
       "      <td>86092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RoadGeek_MD99</td>\n",
       "      <td>475877</td>\n",
       "      <td>81261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Memoire</td>\n",
       "      <td>2176227</td>\n",
       "      <td>56464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name  user_id  contributions\n",
       "0  woodpeck_fixbot   147510         565052\n",
       "1         TexasNHD   672878         538407\n",
       "2         afdreher  1110270         486780\n",
       "3          scottyc   496606         204136\n",
       "4          cammace  3119079         193856\n",
       "5      claysmalley   119881         138030\n",
       "6        brianboru     9065         116780\n",
       "7          skquinn   243003          86092\n",
       "8    RoadGeek_MD99   475877          81261\n",
       "9          Memoire  2176227          56464"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "top_10_df = pd.read_sql_query(\"\"\" \n",
    "                SELECT user_name, user_id, COUNT(user_id) AS contributions \n",
    "                FROM users\n",
    "                GROUP BY user_id\n",
    "                ORDER BY contributions DESC\n",
    "                LIMIT 10; \"\"\", db)\n",
    "top_10_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of users who contributed only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(372,)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\" \n",
    "            SELECT COUNT(*) \n",
    "            FROM\n",
    "                (SELECT user_id, COUNT(user_id) as num \n",
    "                FROM users\n",
    "                GROUP BY user_id\n",
    "                HAVING num = 1) one_time_users; \"\"\").fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amenities in Houston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place_of_worship</td>\n",
       "      <td>2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>school</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fountain</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fast_food</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fire_station</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fuel</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pharmacy</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bank</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>police</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              value   num\n",
       "0  place_of_worship  2220\n",
       "1            school   823\n",
       "2          fountain   713\n",
       "3        restaurant   703\n",
       "4         fast_food   641\n",
       "5      fire_station   351\n",
       "6              fuel   279\n",
       "7          pharmacy   177\n",
       "8              bank   173\n",
       "9            police   161"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amenities_df = pd.read_sql_query(\"\"\"SELECT value, COUNT(*) as num\n",
    "                            FROM nodes_tags\n",
    "                            WHERE key='amenity'\n",
    "                            GROUP BY value\n",
    "                            ORDER BY num DESC\n",
    "                            LIMIT 10;\"\"\", db)\n",
    "amenities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place of worship, schools and Fountains(Surprise!) takes the top places in above table. \n",
    "Lets look at which religion is practiced the most. \n",
    "\n",
    "### Religion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'christian', 2151),\n",
       " (u'buddhist', 16),\n",
       " (u'jewish', 12),\n",
       " (u'muslim', 9),\n",
       " (u'unitarian_universalist', 5)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\" SELECT nodes_tags.value, COUNT(*) as num\n",
    "                FROM nodes_tags \n",
    "                JOIN \n",
    "                (SELECT DISTINCT(id) FROM nodes_tags WHERE value='place_of_worship') i\n",
    "                ON nodes_tags.id=i.id\n",
    "                WHERE nodes_tags.key='religion'\n",
    "                GROUP BY nodes_tags.value\n",
    "                ORDER BY num DESC;\"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christianity! No Surprise there!\n",
    "\n",
    "### Restaurants - Most popular cuisine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'mexican', 74),\n",
       " (u'american', 36),\n",
       " (u'pizza', 33),\n",
       " (u'italian', 32),\n",
       " (u'chinese', 28),\n",
       " (u'seafood', 22),\n",
       " (u'burger', 19),\n",
       " (u'barbecue', 16),\n",
       " (u'sandwich', 13),\n",
       " (u'thai', 10)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\" \n",
    "                SELECT nodes_tags.value, COUNT(*) as num\n",
    "                FROM nodes_tags \n",
    "                JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i\n",
    "                ON nodes_tags.id=i.id\n",
    "                WHERE nodes_tags.key='cuisine'\n",
    "                GROUP BY nodes_tags.value\n",
    "                ORDER BY num DESC\n",
    "                LIMIT 10;\"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was predictable. Let us also look at how many Starbucks are there in Houston. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64,)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\" SELECT COUNT(*) as num \n",
    "                FROM nodes_tags WHERE value='Starbucks';\"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 64 Starbucks in Houston Area.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(831,)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\"SELECT COUNT(*) AS num\n",
    "FROM nodes_tags\n",
    "WHERE nodes_tags.value = 'school';\"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 831 schools in Houston Area.\n",
    "\n",
    "### Source of Data\n",
    "In order to get the sources of data, I first created a table of all values for which key is source and their count from both nodes_tags as well as ways_tags. And then query the table to get the number of records for different sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x9563c00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS allsources;\")\n",
    "\n",
    "cur.execute(\"\"\" CREATE TABLE allsources AS\n",
    "                SELECT value, count(*) AS num\n",
    "                FROM\n",
    "                (SELECT value \n",
    "                FROM nodes_tags\n",
    "                WHERE nodes_tags.key = 'source'\n",
    "                GROUP BY value\n",
    "                        \n",
    "                UNION ALL\n",
    "                        \n",
    "                SELECT value \n",
    "                FROM ways_tags\n",
    "                WHERE ways_tags.key = 'source'\n",
    "                GROUP BY value) source\n",
    "                GROUP BY source.value\n",
    "                ORDER BY num DESC\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data was not initially cleaned for source tags, so I used %bing% or 'Bing%, etc. to find its matches in the tag fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18,)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\" SELECT SUM(num) AS bing\n",
    "                FROM\n",
    "                (SELECT * FROM allsources\n",
    "                WHERE value LIKE 'Bing%' OR value LIKE '%bing%') b\"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I queried separately for different sources and numbers are shown below. \n",
    "```\n",
    "Bing - 18\n",
    "Tiger - 10\n",
    "Wikipedia - 2\n",
    "GPS - 7\n",
    "Yahoo - 7\n",
    "Google - 1```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Ideas \n",
    "\n",
    "### Postcode validation\n",
    "While auditing the file, we came across so many different formats for postcodes being used. Not just the formats of postcode, but we also obseved there was mismatch of city and postcode. In my opinion the city and the postcode should be cross checked for validation at the point of entry by the user. There are many public APIs to retrieve addresses from postcode. If implemented, this will prevent a huge amount of incorrect data inputs and will bring consistency in the format too.  In turn, it will help save a lot of time and effort in data cleaning and it will be lot less inconvinience for the people who use the OpenStreet Map. \n",
    "\n",
    "Another viable solution could be to use location data from mobiles of the users who are logged in. If the location is already in the file, the user will be asked to verify the location details of the place or else input the address details. It is also possible that some users may not want to share their location data, so this can be used as an opt in option for the users. In effect, it may also increase the number of contributions from not so regular contributors if given an opportunity for a quick add/validate option. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://wiki.openstreetmap.org/wiki/Main_Page\n",
    "2. https://mapzen.com/data/metro-extracts/\n",
    "3. https://www.dataquest.io/blog/python-pandas-databases/\n",
    "4. https://discussions.udacity.com/t/creating-db-file-from-csv-files-with-non-ascii-unicode-characters/174958/7\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
